{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage Examples\n",
    "\n",
    "This notebook provides examples of the core functionality of `nbtest`. Notebooks that use `nbtest` must first load the extension as shown in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nbtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags begin with the `@` symbol and should be legal Python identifiers (after the @). Tags found in the docstring (e.g. `@answer1`) of the cell are added to the cell cache. The cell can be re-run by test code so cells like `@answer1` should not assign variables if test code will modify them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables in the notebook\n",
    "a = 100 \n",
    "b = 200 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a solution cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"@answer1\"\"\"\n",
    "\n",
    "print(\"Hello World\")\n",
    "a < b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can introspect and run cells easily using the API for `nbtest`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer source: '\"\"\"@answer1\"\"\"\\n\\nprint(\"Hello World\")\\na < b\\n'\n",
      "Answer result: <class 'IPython.core.interactiveshell.ExecutionResult'>\n",
      "Answer result value: True\n",
      "Re-run answer result: False\n",
      "Original result value: True\n"
     ]
    }
   ],
   "source": [
    "import nbtest\n",
    "\n",
    "answer1 = nbtest.get('@answer1')\n",
    "print(\"Answer source:\", repr(answer1.source))\n",
    "print(\"Answer result:\", type(answer1.result))\n",
    "print(\"Answer result value:\", answer1.result.result)\n",
    "\n",
    "\n",
    "a = 200\n",
    "b = 100 \n",
    "result = answer1.run()\n",
    "print(\"Re-run answer result:\", result.result)\n",
    "\n",
    "# run() doesn't affect the cache.\n",
    "print(\"Original result value:\", answer1.result.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TagCacheEntry in module nbtest.tagcache object:\n",
      "\n",
      "class TagCacheEntry(builtins.object)\n",
      " |  TagCacheEntry(result, shell)\n",
      " |\n",
      " |  Information about an executed cell.\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, result, shell)\n",
      " |      Create an entry.\n",
      " |\n",
      " |  run(self, push: Mapping = {}, capture: bool = True) -> Optional[nbtest.tagcache.CellRunResult]\n",
      " |      Run the contents of a cached cell.\n",
      " |\n",
      " |      push: Update variables in the notebook namespace with names and values in `push` before running the contents.\n",
      " |      capture: Set to `True` (the default) to capture stdout, stderr and output. If `False` run() returns `None`\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  docstring\n",
      " |      The docstring of the cell or `None` if there is no docstring.\n",
      " |\n",
      " |  id\n",
      " |      The unique identifier of the notebook cell.\n",
      " |\n",
      " |  result\n",
      " |      The ExecutionResult from running the cell in IPython.\n",
      " |\n",
      " |  source\n",
      " |      The processed source of the cell.\n",
      " |\n",
      " |  tags\n",
      " |      A set of the tags found in the cell.\n",
      " |\n",
      " |  tokens\n",
      " |      A set of token classes from the parsed source.\n",
      " |\n",
      " |  tree\n",
      " |      The parse tree generated from parsing the cell source. See ast.parse()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on CellRunResult in module nbtest.tagcache object:\n",
      "\n",
      "class CellRunResult(builtins.object)\n",
      " |  CellRunResult(stdout: str, stderr: str, outputs: list[typing.Any], result: Any) -> None\n",
      " |\n",
      " |  The result of calling run() on a TagCacheEntry\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __init__(self, stdout: str, stderr: str, outputs: list[typing.Any], result: Any) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'outputs': list[typing.Any], 'result': typing.Any, ...\n",
      " |\n",
      " |  __dataclass_fields__ = {'outputs': Field(name='outputs',type=list[typi...\n",
      " |\n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=True,or...\n",
      " |\n",
      " |  __hash__ = None\n",
      " |\n",
      " |  __match_args__ = ('stdout', 'stderr', 'outputs', 'result')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Notebook Cells \n",
    "\n",
    "The `run()` function returns a `CellRunResult` object that, by default, contains the outputs, stdout and stderr generated by running the cell. Re-running a cell with `run()` does not affect the cached copy that was run in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell stdout: 'Hello World\\n'\n",
      "Cell stderr: ''\n",
      "Cell result: False\n",
      "Cell outputs: [False]\n"
     ]
    }
   ],
   "source": [
    "result = answer1.run()\n",
    "print(\"Cell stdout:\", repr(result.stdout))\n",
    "print(\"Cell stderr:\", repr(result.stderr))\n",
    "print(\"Cell result:\", result.result)\n",
    "print(\"Cell outputs:\", result.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `run()` function can set variables in the notebook context to simplify testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 < 2 == True\n",
      "2 < 2 == False\n"
     ]
    }
   ],
   "source": [
    "print(\"1 < 2 ==\", answer1.run({'a': 1, 'b': 2}).result)\n",
    "print(\"2 < 2 ==\", answer1.run({'a': 2, 'b': 2}).result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the `run()` function captures stdout and stderr as well as any cell outputs. If you want output from running the cell to be processed the usual way in the notebook pass in `capture=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer1.run(capture=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When `capture` is `False` the `run()` function returns `None` instead of a `CellRunResult`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `%%testing` Cell Magic\n",
    "\n",
    "The `%%testing` cell magic provides a wrapper for test code. `%%testing` cells render feedback for students. Tests run in a separate module namespace, just as they would for normal unit tests. Attributes listed after the testing cell magic are imported into the test namespace so they are available to test code. Imports in testing cells are not shared with the rest of the notebook.\n",
    "\n",
    "Assertions are a convenient way to do simple checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em; margin-top: 0.5em\">\n",
       "    \n",
       "        ✅ All tests passed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1\n",
    "\n",
    "import ast \n",
    "\n",
    "# The `answer1` variable contains the cell cache entry \n",
    "assert ast.Lt in answer1.tokens, \"I don't see less than!\"\n",
    "assert ast.Gt not in answer1.tokens, \"I see greater than!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cells always succeed, unless there's a problem with the test code. When tests fail students are shown your messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 0.5em; margin-top: 0.5em\">\n",
       "    ⚠️ Attention needed.\n",
       "</div>\n",
       "<div>\n",
       "    The answer doesn&#39;t contain the a less than sign.\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1\n",
    "\n",
    "# Failures don't stop the cell.\n",
    "assert ast.Lt not in answer1.tokens, \"The answer doesn't contain the a less than sign.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since test code runs in a separate namespace it's required to use `shell.push()` to set variables in the notebook namespace. The `run()` function can also set variables in the notebook namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em; margin-top: 0.5em\">\n",
       "    \n",
       "        ✅ All tests passed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1\n",
    "\n",
    "# The `shell` variable contains the interactive shell.\n",
    "shell.push({'a': 1, 'b': 2}) \n",
    "assert answer1.run().result == True, \"1 < 2 != True\"\n",
    "\n",
    "# `run()` optionally pushes variables too.\n",
    "assert answer1.run({'a': 3, 'b': 2}).result == False, \"3 < 2 != False\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an attribute is missing the testing cell provides helpful feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; padding-bottom: 0.5em; margin-top: 0.5em\">\n",
       "    ⚠️ Solution not found.\n",
       "</div>\n",
       "<div>\n",
       "    The name <span style=\"font-family: monospace;\">&#39;bogus&#39;</span> is missing. Have you run all cells?\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing bogus \n",
    "\n",
    "# Bad params cause an error. \n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Methods \n",
    "\n",
    "Functions that begin with `test` become test cases. Test cases are run and results are rendered below the cell. Test results use the docstring of test functions and assertion errors to inform the student how to fix their problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em; margin-top: 0.5em\">\n",
       "    \n",
       "        ⚠️ Attention needed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em; color: red; font-weight: bold;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">1 &lt; 2 != True</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">The function <span style=\"font-family: monospace\">test_broken_nodoc()</span> reported an error.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em; color: red; font-weight: bold;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">1 &lt; 2 != True</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">The test description is used to provide feedback to the learner. They will see this message when the test fails. It's useful to put a hint here.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1\n",
    "\n",
    "# Functions that start with `test` become a `FunctionTestCase`\n",
    "def test_lt(): \n",
    "    \"\"\"Testing less than.\"\"\"\n",
    "    assert answer1.run({'a': 1, 'b': 2}).result == True, \"1 < 2 != True\"\n",
    "    assert answer1.run({'a': 3, 'b': 2}).result == False, \"3 < 2 != False\"    \n",
    "\n",
    "def test_broken_nodoc(): \n",
    "    assert answer1.run({'a': 1, 'b': 2}).result == False, \"1 < 2 != True\"\n",
    "\n",
    "def test_broken_withdoc(): \n",
    "    \"\"\"The test description is used to provide feedback to the learner. They will see this message when the test fails. It's useful to put a hint here.\"\"\"\n",
    "    assert answer1.run({'a': 1, 'b': 2}).result == False, \"1 < 2 != True\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing cell source is useful but solutions may contain variables, classes or functions. Those can be tested too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@answer2\"\"\"\n",
    "\n",
    "def add(a, b):\n",
    "    \"\"\"My solution function\"\"\"\n",
    "    return a + b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When solutions contain symbols they must be added to the testing magic to be present in the test namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em; margin-top: 0.5em\">\n",
       "    \n",
       "        ⚠️ Attention needed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em; color: red; font-weight: bold;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">TypeError: unsupported operand type(s) for +: &#39;int&#39; and &#39;str&#39;</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">This is a description of the error that has happened.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing add\n",
    "\n",
    "# Attributes must be listed to be present in the test namespace.\n",
    "assert add.__doc__ is not None, \"add() doesn't have a docstring.\"\n",
    "\n",
    "def test_add():\n",
    "    assert add(1,2) == 3, \"1 + 2 != 3\"\n",
    "    assert add(-2,-2) == -4, \"-2 + -2 != -4\"\n",
    "    assert add(1,-3) == -2, \"1 + -3 != -2\"\n",
    "\n",
    "def test_err():\n",
    "    \"\"\"This is a description of the error that has happened.\"\"\"\n",
    "    assert add(0,\"bogus\"), \"This is a bogus test.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Tests \n",
    "\n",
    "The test functions are based on Python's `unittest`. Any classes in a testing cell that derive form `unittest.TestCase` are automatically run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em; margin-top: 0.5em\">\n",
       "    \n",
       "        ⚠️ Attention needed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em; color: red; font-weight: bold;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">3 != 0 : add(1,2)</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">Bad test with documentation.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em; color: red; font-weight: bold;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">3 != 0 : add(1,2)</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">The function <span style=\"font-family: monospace\">TestAdd.test_badd_nodoc()</span> reported an error.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing add \n",
    "\n",
    "# Get the full power of TestCase (or write your own)\n",
    "\n",
    "import unittest\n",
    "\n",
    "class TestAdd(unittest.TestCase):\n",
    "\n",
    "    def test_add(self):\n",
    "        self.assertEqual(add(1,2), 3, \"add(1,2)\")\n",
    "        self.assertEqual(add(-2,-2), -4, \"add(-2,-2)\")\n",
    "        self.assertEqual(add(1,-3), -2, \"add(-1,-3)\")\n",
    "\n",
    "    def test_badd_nodoc(self):\n",
    "        self.assertEqual(add(1,2), 0, \"add(1,2)\")\n",
    "\n",
    "    def test_badd_doc(self):\n",
    "        \"\"\"Bad test with documentation.\"\"\"\n",
    "        self.assertEqual(add(1,2), 0, \"add(1,2)\")\n",
    "\n",
    "    def test_skip_me(self):\n",
    "        self.skipTest(\"This test isn't relevant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The symbol `nbtest_attrs` is a dictionary that contains the attributes given to the `%%testing` cell magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute: answer1 value: <nbtest.tagcache.TagCacheEntry object at 0x768cf0fe7890>\n",
      "Attribute: answer2 value: <nbtest.tagcache.TagCacheEntry object at 0x768cf0fe7530>\n",
      "Attribute: add value: <function add at 0x768cf19ab380>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em; margin-top: 0.5em\">\n",
       "    \n",
       "        ✅ All tests passed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1 @answer2 add\n",
    "\n",
    "from nbtest import nbtest_attrs\n",
    "\n",
    "for attr in nbtest_attrs:\n",
    "    print(f\"Attribute: {attr} value: {nbtest_attrs[attr]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Severity Signaling \n",
    "\n",
    "The `nbtest` module contains three decorators, `info`, `warning` and `error`. Decorating a test function with one of the decorators changes the style of the output feedback. Severity feedback can help students understand what to pay most attention to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em; margin-top: 0.5em\">\n",
       "    \n",
       "        ⚠️ Attention needed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em;\">ℹ️</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">1 &lt; 2 != True</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">There is something that requires a look but is not necessarily an error.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em;\">⚠️</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">1 &lt; 2 != True</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">This demands attention and is probably an error but maybe not.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em; color: red; font-weight: bold;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">1 &lt; 2 != True</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">An error has happened.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em; color: red; font-weight: bold;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">1 &lt; 2 != True</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">Unless otherwise specified, a failure is an error.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1\n",
    "\n",
    "from nbtest import info, warning, error\n",
    "\n",
    "# Functions that start with `test` become a `FunctionTestCase`\n",
    "@info\n",
    "def test_info(): \n",
    "    \"\"\"There is something that requires a look but is not necessarily an error.\"\"\"\n",
    "    assert answer1.run({'a': 2, 'b': 2}).result == True, \"1 < 2 != True\"\n",
    "\n",
    "@warning\n",
    "def test_warning(): \n",
    "    \"\"\"This demands attention and is probably an error but maybe not.\"\"\"\n",
    "    assert answer1.run({'a': 2, 'b': 2}).result == True, \"1 < 2 != True\"\n",
    "\n",
    "@error\n",
    "def test_error(): \n",
    "    \"\"\"An error has happened.\"\"\"\n",
    "    assert answer1.run({'a': 2, 'b': 2}).result == True, \"1 < 2 != True\"\n",
    "\n",
    "def test_also_error(): \n",
    "    \"\"\"Unless otherwise specified, a failure is an error.\"\"\"\n",
    "    assert answer1.run({'a': 2, 'b': 2}).result == True, \"1 < 2 != True\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
