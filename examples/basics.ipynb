{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Usage \n",
    "\n",
    "All the basics of making test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nbtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags begin with the `@` symbol. If there's a Python identifier compatible tag in the docstring (e.g. `@answer1`) the cell is added to the cell cache. The cell can be re-run by test code so cells like `@answer1` should not assign variables so they can be modified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 100 \n",
    "b = 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"@answer1\"\"\"\n",
    "\n",
    "a < b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can introspect and run cells easily using the API for `nbtest`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer source: \"\"\"@answer1\"\"\"\n",
      "\n",
      "a < b\n",
      "\n",
      "Answer result: <class 'IPython.core.interactiveshell.ExecutionResult'>\n",
      "Answer result value: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-run answer: False\n",
      "Original result value: True\n"
     ]
    }
   ],
   "source": [
    "import nbtest\n",
    "\n",
    "answer1 = nbtest.find('@answer1')\n",
    "print(\"Answer source:\", answer1.source)\n",
    "print(\"Answer result:\", type(answer1.result))\n",
    "print(\"Answer result value:\", answer1.result.result)\n",
    "\n",
    "a = 200\n",
    "b = 100 \n",
    "print(\"Re-run answer:\", answer1.run())\n",
    "\n",
    "# run() doesn't affect the cache.\n",
    "print(\"Original result value:\", answer1.result.result)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%%testing` cell magic provides an important wrapper for test code. Testing cells render feedback for students. Tests run in a separate module namespace, just as they would for normal unit tests. Attributes listed after the testing cell magic are imported into the test namespace so they are available to test code. Imports in testing cells are not shared with the rest of the notebook.\n",
    "\n",
    "Assertions are a convenient way to do simple checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em\">\n",
       "    \n",
       "        ✅ All tests passed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1\n",
    "\n",
    "import ast \n",
    "\n",
    "# The `answer1` variable contains the cell cache entry \n",
    "assert ast.Lt in answer1.tokens, \"I don't see less than!\"\n",
    "assert ast.Gt not in answer1.tokens, \"I see greater than!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cells always succeed, unless there's a problem with the test code. If there's a problem students are shown your messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 0.5em\">\n",
       "    ⚠️ Attention needed.\n",
       "</div>\n",
       "<div>\n",
       "    The answer doesn&#39;t contain the a less than sign.\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1\n",
    "\n",
    "# Failures don't stop the cell.\n",
    "assert ast.Lt not in answer1.tokens, \"The answer doesn't contain the a less than sign.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `shell.push()` to set variables in the notebook namespace. The `run()` function is a convenience for running notebook cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em\">\n",
       "    \n",
       "        ✅ All tests passed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1\n",
    "\n",
    "# The `shell` variable contains the interactive shell.\n",
    "shell.push({'a': 1, 'b': 2}) \n",
    "assert answer1.run() == True, \"1 < 2 != True\"\n",
    "\n",
    "# `run()` optionally pushes variables too.\n",
    "assert answer1.run({'a': 3, 'b': 2}) == False, \"3 < 2 != False\"\n",
    "\n",
    "# Output from running the cell is below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that begin with `test` become test cases. Test cases are run and results are rendered below the cell. Test results use the docstring of test functions and assertion errors to inform the student how to fix their problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em\">\n",
       "    \n",
       "        ⚠️ Attention needed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">1 &lt; 2 != True</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">The function <span style=\"font-family: monospace\">test_broken_nodoc()</span> reported an error.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">1 &lt; 2 != True</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">The test description is used to provide feedback to the learner. They will see this message when the test fails. It's useful to put a hint here.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1\n",
    "\n",
    "# Functions that start with `test` become a `FunctionTestCase`\n",
    "def test_lt(): \n",
    "    \"\"\"Testing less than.\"\"\"\n",
    "    assert answer1.run({'a': 1, 'b': 2}) == True, \"1 < 2 != True\"\n",
    "    assert answer1.run({'a': 3, 'b': 2}) == False, \"3 < 2 != False\"    \n",
    "\n",
    "def test_broken_nodoc(): \n",
    "    assert answer1.run({'a': 1, 'b': 2}) == False, \"1 < 2 != True\"\n",
    "\n",
    "def test_broken_withdoc(): \n",
    "    \"\"\"The test description is used to provide feedback to the learner. They will see this message when the test fails. It's useful to put a hint here.\"\"\"\n",
    "    assert answer1.run({'a': 1, 'b': 2}) == False, \"1 < 2 != True\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing cell source is useful but solutions may contain variables, classes or functions. Those can be tested too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@answer2\"\"\"\n",
    "\n",
    "def add(a, b):\n",
    "    \"\"\"My solution function\"\"\"\n",
    "    return a + b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When solutions contain symbols they must be added to the testing magic to be present in the test namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em\">\n",
       "    \n",
       "        ⚠️ Attention needed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">TypeError: unsupported operand type(s) for +: &#39;int&#39; and &#39;str&#39;</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">This is a description of the error that has happened.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing add\n",
    "\n",
    "# Attributes must be listed to be present in the test namespace.\n",
    "assert add.__doc__ is not None, \"add() doesn't have a docstring.\"\n",
    "\n",
    "def test_add():\n",
    "    assert add(1,2) == 3, \"1 + 2 != 3\"\n",
    "    assert add(-2,-2) == -4, \"-2 + -2 != -4\"\n",
    "    assert add(1,-3) == -2, \"1 + -3 != -2\"\n",
    "\n",
    "def test_err():\n",
    "    \"\"\"This is a description of the error that has happened.\"\"\"\n",
    "    assert add(0,\"bogus\"), \"This is a bogus test.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test functions are based on Python's `unittest`. Any classes in a testing cell that derive form `unittest.TestCase` are automatically run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em\">\n",
       "    \n",
       "        ⚠️ Attention needed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">3 != 0 : add(1,2)</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">Bad test with documentation.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "        <div style=\"width: 75%; min-width: 500px; max-width: 800px; padding-left: 50px; padding-bottom: 2rem\">\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; padding: 0.25em;\">\n",
       "                    \n",
       "                        <span style=\"font-size: x-large; padding: 0.25em;\">❌</span>\n",
       "                    \n",
       "                    <span style=\"font-family: monospace;\">3 != 0 : add(1,2)</span>\n",
       "                </div>    \n",
       "            </div>\n",
       "            <div style=\"clear: both;\">\n",
       "                <div style=\"float: left; vertical-align: middle; padding-top: 0.25em; padding-bottom: 1em;\">The function <span style=\"font-family: monospace\">TestAdd.test_badd_nodoc()</span> reported an error.</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing add \n",
    "\n",
    "# Get the full power of TestCase (or write your own)\n",
    "\n",
    "import unittest\n",
    "\n",
    "class TestAdd(unittest.TestCase):\n",
    "\n",
    "    def test_add(self):\n",
    "        self.assertEqual(add(1,2), 3, \"add(1,2)\")\n",
    "        self.assertEqual(add(-2,-2), -4, \"add(-2,-2)\")\n",
    "        self.assertEqual(add(1,-3), -2, \"add(-1,-3)\")\n",
    "\n",
    "    def test_badd_nodoc(self):\n",
    "        self.assertEqual(add(1,2), 0, \"add(1,2)\")\n",
    "\n",
    "    def test_badd_doc(self):\n",
    "        \"\"\"Bad test with documentation.\"\"\"\n",
    "        self.assertEqual(add(1,2), 0, \"add(1,2)\")\n",
    "\n",
    "    def test_skip_me(self):\n",
    "        self.skipTest(\"This test isn't relevant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an attribute is missing the testing cell provides helpful feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; padding-bottom: 0.5em\">\n",
       "    ⚠️ Solution not found.\n",
       "</div>\n",
       "<div>\n",
       "    The name <span style=\"font-family: monospace;\">&#39;bogus&#39;</span> is missing. Have you run all cells?\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing bogus \n",
    "\n",
    "# Bad params cause an error. \n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The symbol `nbtest_attrs` is a dictionary that contains the attributes given to the `%%testing` cell magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute: answer1 value: <nbtest.cache.CacheEntry object at 0x7436b0547760>\n",
      "Attribute: answer2 value: <nbtest.cache.CacheEntry object at 0x7436b0547ac0>\n",
      "Attribute: add value: <function add at 0x7436b028ee60>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-size: large; font-weight: bold; margin-bottom: 1em\">\n",
       "    \n",
       "        ✅ All tests passed.\n",
       "        \n",
       "</div>\n",
       "<div>\n",
       "    \n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%testing @answer1 @answer2 add\n",
    "\n",
    "from nbtest import nbtest_attrs\n",
    "\n",
    "for attr in nbtest_attrs:\n",
    "    print(f\"Attribute: {attr} value: {nbtest_attrs[attr]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
